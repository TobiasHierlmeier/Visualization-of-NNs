{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Playground Notebook for visualization of Neural Networks in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import _base\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset 1 -  Digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_digits()\n",
    "X = d['data']\n",
    "y = d['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[10,:].reshape(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define potential Layer Sizes for a wide variety of MLP architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all permutations of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archs = []\n",
    "for i in range(1, 6):\n",
    "    archs.extend([p for p in itertools.product(layer_sizes, repeat=i)])\n",
    "print(len(archs))\n",
    "archs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Result-saving in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Train Accuracy', 'Test Accuracy', 'Model'], index=archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in tqdm_notebook(archs):\n",
    "    model = MLPClassifier(hidden_layer_sizes=arch, verbose=False, max_iter=500, activation='relu', solver='adam')\n",
    "    model.fit(X_train, y_train)\n",
    "    df.loc[arch, 'Train Accuracy'] = accuracy_score(model.predict(X_train), y_train)\n",
    "    df.loc[arch, 'Test Accuracy'] = accuracy_score(model.predict(X_test), y_test)\n",
    "    df.loc[arch, 'Model'] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Results and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Test Accuracy', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(6,8))\n",
    "results.iloc[::-1].plot.barh(ax=ax, color=['darkblue', 'lightgreen'])\n",
    "ax.axvline(x=results['Test Accuracy'].max(), ymin = 0, ymax = 1, linewidth = 1.2, color = 'black', linestyle = ':')\n",
    "ax.text(x=results['Test Accuracy'].max()-.2, y=19.7, s='Test-Acc: {:.4f}'.format(results['Test Accuracy'].max()),\n",
    "        FontSize=13)\n",
    "ax.legend(loc='best', bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "for i in range(len(results)//4):\n",
    "    loss_curve = results['Model'].iloc[i].loss_curve_\n",
    "    ax.plot(loss_curve, label=results['Model'].iloc[i].hidden_layer_sizes)\n",
    "    ax.set(ylabel='Loss', xlabel='Epochs')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feature Maps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = results['Model'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reconstruct default matplotlib params for image plotting  \n",
    "# matplotlib.rcParams['image.interpolation'] = None\n",
    "# matplotlib.rcParams['image.cmap'] = 'viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_perfect_square(n):\n",
    "    x = n // 2\n",
    "    y = set([x])\n",
    "    while x * x != n:\n",
    "        x = (x + (n // x)) // 2\n",
    "        if x in y: \n",
    "            return False, x\n",
    "        y.add(x)\n",
    "    return True, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(image, y_true, model):\n",
    "\n",
    "    activation_func = eval('_base.'+model.activation)\n",
    "    output_act_func = eval('_base.'+model.out_activation_)\n",
    "    \n",
    "    input_img = image\n",
    "    _, ax1 = plt.subplots(figsize=(16,4))\n",
    "    ax1.imshow(input_img.reshape(8, 8))\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_hat = model.predict(input_img.reshape(1,-1))\n",
    "    \n",
    "    n_hidden_layers = len(model.hidden_layer_sizes)\n",
    "        \n",
    "    outs = []\n",
    "    outs.append(activation_func(np.matmul(input_img, model.coefs_[0]) + model.intercepts_[0]))\n",
    "    for i in range(1, n_hidden_layers):            \n",
    "        outs.append(activation_func(np.matmul(outs[i-1], model.coefs_[i]) + model.intercepts_[i]))\n",
    "    outs.append(output_act_func((np.matmul(outs[-1], model.coefs_[-1]) + model.intercepts_[-1]).reshape(1,-1)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16,4), ncols=len(outs))\n",
    "\n",
    "    for i, out in enumerate(outs):\n",
    "        N = out\n",
    "        siz = np.sqrt(N.shape[0])\n",
    "\n",
    "        if i==(len(outs)-1):\n",
    "            ax[-1].imshow(N.reshape(1, 10))\n",
    "        else:\n",
    "            answer, val = is_perfect_square(N.size)\n",
    "            if answer:\n",
    "                ax[i].imshow(N.reshape(val, val))\n",
    "            else:\n",
    "                M = N.copy()\n",
    "                M.resize(val,val+1)\n",
    "                ax[i].imshow(M, resample=True)\n",
    "            ax[i].set(xticks=[], yticks=[], title='Output Hidden Layer {}'.format(i+1))\n",
    "            \n",
    "    ax[-1].set(title='Output Layer\\ny_Pred = {}, y_TRUE = {}'.format(y_hat, y_true), yticks=[],\n",
    "              xticks=[i for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom Neural Network\n",
    "Visualization works best with quadratic hidden layer sizes (e.g. [16, 64, 256]); There won't be any lines, edges, shapes in the visualization, because the architecture is a fully-connected network, without any convolutional layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if custom NN desired:\n",
    "custom_arch = (256, 256, 256)\n",
    "model = MLPClassifier(hidden_layer_sizes=custom_arch, verbose=False, max_iter=500, activation='relu', solver='adam')\n",
    "model.fit(X_train, y_train)\n",
    "print('Train ACC: {:.4f}'.format(accuracy_score(model.predict(X_train), y_train)))\n",
    "print('Test ACC: {:.4f}'.format(accuracy_score(model.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any Prediciton Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice([i for i in range(len(X))])\n",
    "feedforward(X[sample], y[sample], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong Prediciton Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "mask = y_hat == y_test\n",
    "mask = mask.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_indices = []\n",
    "for i, pred in enumerate(mask):\n",
    "    if not pred:\n",
    "        false_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(false_indices) # [0 ... 1796]\n",
    "feedforward(X_test[sample], y_test[sample], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Another Dataset from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow', scattersize=3):\n",
    "    plt.figure(figsize=(12,12));\n",
    "    ax = ax or plt.gca();\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=scattersize, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3);\n",
    "    ax.axis('tight');\n",
    "    ax.axis('off');\n",
    "    xlim = ax.get_xlim();\n",
    "    ylim = ax.get_ylim();\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200));\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape);\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y));\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1);\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim, aspect='equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_MLP_Layers(model, X, y, figsize='auto', xlim=(-1.5, 1.5), ylim=(-1.5, 1.5), cmap='coolwarm', title='on',\n",
    "                    scattersizes=3):\n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "        model:        a sklearn.neural_networks.MLPClassifier model\n",
    "        X:            Features\n",
    "        y:            Labels\n",
    "        figsize:      e.g (16, 16); default='auto'\n",
    "        xlim:         x-axis-limits; default=(-1.5, 1.5)\n",
    "        ylim:         y-axis-limits; default=(-1.5, 1.5)\n",
    "        cmap:         matplotlib-colormap; default='coolwarm'\n",
    "        title:        shows title (#Layer, #Node) of every subplot; default='on'; options= 'on', 'off'\n",
    "        scattersizes: determines the size of the points in the scatterplots.\n",
    "    OUTPUT:\n",
    "        Plots Feature Maps of every node in a MLP.\n",
    "    \"\"\"\n",
    "    # Grab number of hidden layers and set automated figure size:\n",
    "    n_hidden_layers = len(model.hidden_layer_sizes)\n",
    "    if figsize == 'auto':\n",
    "        figsize = (n_hidden_layers*4, int(max(model.hidden_layer_sizes)*2))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, nrows=max(model.hidden_layer_sizes), ncols=n_hidden_layers+1);\n",
    "    \n",
    "    # Grab Activation Functions:\n",
    "    activation_func = eval('_base.'+model.activation)\n",
    "    output_act_func = eval('_base.'+model.out_activation_)\n",
    "\n",
    "    # Initialize mesh for decision boundarys of MLP:\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200));\n",
    "    input_mesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Feedforward Input:\n",
    "    outs = []\n",
    "    outs.append(activation_func(np.matmul(input_mesh, model.coefs_[0]) + model.intercepts_[0]))\n",
    "    for i in range(1, n_hidden_layers):\n",
    "        outs.append(activation_func(np.matmul(outs[-1], model.coefs_[i]) + model.intercepts_[i]))\n",
    "    outs.append((np.matmul(outs[-1], model.coefs_[-1]) + model.intercepts_[-1]))\n",
    "\n",
    "    # Plot Outputs of every node in every layer:\n",
    "    n_classes = len(np.unique(y));\n",
    "    for layer in range(len(model.hidden_layer_sizes)):\n",
    "        for node in range(model.hidden_layer_sizes[layer]):\n",
    "            # Plot the training points\n",
    "            ax[node][layer].scatter(X[:, 0], X[:, 1], c=y, s=scattersizes, cmap=cmap,\n",
    "                       clim=(y.min(), y.max()), zorder=0);\n",
    "            ax[node][layer].axis('off');\n",
    "            ax[node][layer].axis('tight');\n",
    "\n",
    "            contours = ax[node][layer].contourf(xx, yy, output_act_func(outs[layer][:,node]).reshape(xx.shape), alpha=0.3,\n",
    "                                   levels=np.arange(n_classes + 1) - 0.5, cmap=cmap, clim=(y.min(), y.max()), zorder=2);\n",
    "            ax[node][layer].set(aspect='equal')\n",
    "            if title == 'on':\n",
    "                ax[node][layer].set_title('L{}, Node{}'.format(layer+1, node+1))\n",
    "            else:\n",
    "                ax[0][layer].set_title('Layer {}'.format(layer+1))\n",
    "    ax[0][-1].set(aspect='equal', title='Output')\n",
    "    visualize_classifier(model, X, y, ax=ax[0][-1], cmap='coolwarm', scattersize=scattersizes)\n",
    "\n",
    "    # Remove empty Axes-Objects:\n",
    "    for i in range(n_hidden_layers+1):\n",
    "        for j in range(max(model.hidden_layer_sizes)):\n",
    "            if ax[j][i].has_data() == False:\n",
    "                fig.delaxes(ax[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spirals(n_points, noise=.5):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 1200 * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + (np.random.rand(n_points,1) * noise)\n",
    "    d1y = np.sin(n)*n + (np.random.rand(n_points,1) * noise)\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'A' = 2 circles\n",
    "- 'B' = 2 circular datasets\n",
    "- 'C' = 2 half-moons\n",
    "- 'D' = 2 spirals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_choice_datasets = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import (make_circles, make_blobs, make_moons, make_swiss_roll)\n",
    "N = 2000\n",
    "options = {'A': make_circles(n_samples=N, factor=.6, noise=.1),\n",
    "           'B': make_blobs(n_samples=N, centers=[[-1,-1],[1,1]], n_features=2, cluster_std=1),\n",
    "           'C': make_moons(n_samples=N, noise=.18),\n",
    "           'D': make_spirals(N, noise=1)}\n",
    "Xs, ys = options[your_choice_datasets]\n",
    "sns.scatterplot(x=Xs.T[0], y=Xs.T[1], hue=ys, palette='Dark2')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a MLP, train it, play with its hyperparameters and see results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(32, 32, 32, 16, 8),\n",
    "                      verbose=False, \n",
    "                      max_iter=5000, \n",
    "                      activation='tanh', alpha=0,\n",
    "                      solver='adam')\n",
    "model.fit(X_train, y_train)\n",
    "print('Train Accuracy: {:.4f}'.format(accuracy_score(model.predict(X_train), y_train)))\n",
    "print('Test Accuracy: {:.4f}'.format(accuracy_score(model.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_MLP_Layers(model, Xs[::5], ys[::5], figsize='auto', \n",
    "                xlim=(Xs[:,0].min()-.5, Xs[:,0].max()+.5),\n",
    "                ylim=(Xs[:,1].min()-.5, Xs[:,1].max()+.5),\n",
    "                cmap='coolwarm', title='off', scattersizes=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing other Classifier Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "# model = GradientBoostingClassifier(n_estimators=1000)\n",
    "model = SVC(kernel='rbf', C=.1, gamma='auto')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(model, Xs, ys, ax=None, cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
